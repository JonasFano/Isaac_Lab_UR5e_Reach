wandb_version: 1

_wandb:
  desc: null
  value:
    python_version: 3.10.12
    cli_version: 0.19.9
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1744798744
    t:
      1:
      - 1
      - 55
      - 105
      2:
      - 1
      - 55
      - 105
      3:
      - 14
      - 16
      - 23
      - 35
      - 37
      4: 3.10.12
      5: 0.19.9
      8:
      - 5
      13: linux-x86_64
program:
  desc: null
  value: train_sb3_wandb_ppo.py
method:
  desc: null
  value: grid
name:
  desc: null
  value: rel_ik_sb3_ppo_ur5e_reach_0_05_pose_without_gripper_parameter_optimization_800
metric:
  desc: null
  value:
    goal: maximize
    name: rollout/ep_rew_mean
parameters:
  desc: null
  value:
    seed:
      values:
      - 42
      - 24
    num_envs:
      value: 2048
    n_timesteps:
      value: 104857600
    policy:
      value: MlpPolicy
    n_steps:
      value: 64
    batch_size:
      value: 16384
    gae_lambda:
      value: 0.95
    gamma:
      value: 0.95
    n_epochs:
      value: 8
    ent_coef:
      values:
      - 0.0
      - 0.001
      - 0.01
    vf_coef:
      value: 0.1
    learning_rate:
      values:
      - 0.0001
      - 0.0003
    clip_range:
      value: 0.2
    policy_kwargs:
      parameters:
        activation_fn:
          values:
          - nn.Tanh
          - nn.ReLU
          - nn.ELU
        net_arch:
          parameters:
            pi:
              value:
              - 256
              - 128
            vf:
              value:
              - 256
              - 128
    target_kl:
      value: 0.02
    max_grad_norm:
      value: 1.0
    normalize_input:
      value: false
    normalize_value:
      value: false
    clip_obs:
      value: 50.0
batch_size:
  desc: null
  value: 16384
clip_obs:
  desc: null
  value: 50
clip_range:
  desc: null
  value: 0.2
ent_coef:
  desc: null
  value: 0
gae_lambda:
  desc: null
  value: 0.95
gamma:
  desc: null
  value: 0.95
learning_rate:
  desc: null
  value: 0.0001
max_grad_norm:
  desc: null
  value: 1
n_epochs:
  desc: null
  value: 8
n_steps:
  desc: null
  value: 64
n_timesteps:
  desc: null
  value: 104857600
normalize_input:
  desc: null
  value: false
normalize_value:
  desc: null
  value: false
num_envs:
  desc: null
  value: 2048
policy:
  desc: null
  value: MlpPolicy
policy_kwargs:
  desc: null
  value:
    activation_fn: nn.ReLU
    net_arch:
      pi:
      - 256
      - 128
      vf:
      - 256
      - 128
seed:
  desc: null
  value: 42
target_kl:
  desc: null
  value: 0.02
vf_coef:
  desc: null
  value: 0.1
