wandb_version: 1

_wandb:
  desc: null
  value:
    python_version: 3.10.12
    cli_version: 0.19.9
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1744848843
    t:
      1:
      - 1
      - 55
      - 105
      2:
      - 1
      - 55
      - 105
      3:
      - 1
      - 2
      - 3
      - 14
      - 16
      - 22
      - 23
      - 35
      - 37
      4: 3.10.12
      5: 0.19.9
      8:
      - 5
      13: linux-x86_64
program:
  desc: null
  value: train_sb3_wandb_ppo.py
method:
  desc: null
  value: grid
name:
  desc: null
  value: rel_ik_sb3_ppo_ur5e_reach_0_05_pose_without_gripper_parameter_optimization_800
metric:
  desc: null
  value:
    goal: maximize
    name: rollout/ep_rew_mean
parameters:
  desc: null
  value:
    seed:
      values:
      - 42
      - 24
    num_envs:
      value: 2048
    n_timesteps:
      value: 104857600
    policy:
      value: MlpPolicy
    n_steps:
      value: 64
    batch_size:
      value: 16384
    gae_lambda:
      value: 0.95
    gamma:
      value: 0.95
    n_epochs:
      value: 8
    ent_coef:
      values:
      - 0.0
      - 0.001
      - 0.01
    vf_coef:
      value: 0.1
    learning_rate:
      values:
      - 0.0001
      - 0.0003
    clip_range:
      value: 0.2
    policy_kwargs:
      parameters:
        activation_fn:
          values:
          - nn.Tanh
          - nn.ReLU
          - nn.ELU
        net_arch:
          parameters:
            pi:
              value:
              - 256
              - 128
            vf:
              value:
              - 256
              - 128
    target_kl:
      value: 0.02
    max_grad_norm:
      value: 1.0
    normalize_input:
      value: false
    normalize_value:
      value: false
    clip_obs:
      value: 50.0
batch_size:
  desc: null
  value: 16384
clip_obs:
  desc: null
  value: 50
clip_range:
  desc: null
  value: 0.2
ent_coef:
  desc: null
  value: 0.01
gae_lambda:
  desc: null
  value: 0.95
gamma:
  desc: null
  value: 0.95
learning_rate:
  desc: null
  value: 0.0003
max_grad_norm:
  desc: null
  value: 1
n_epochs:
  desc: null
  value: 8
n_steps:
  desc: null
  value: 64
n_timesteps:
  desc: null
  value: 104857600
normalize_input:
  desc: null
  value: false
normalize_value:
  desc: null
  value: false
num_envs:
  desc: null
  value: 2048
policy:
  desc: null
  value: MlpPolicy
policy_kwargs:
  desc: null
  value:
    activation_fn: nn.Tanh
    net_arch:
      pi:
      - 256
      - 128
      vf:
      - 256
      - 128
seed:
  desc: null
  value: 24
target_kl:
  desc: null
  value: 0.02
vf_coef:
  desc: null
  value: 0.1
algo:
  desc: null
  value: PPO
policy_class:
  desc: null
  value: <class 'stable_baselines3.common.policies.ActorCriticPolicy'>
device:
  desc: null
  value: cuda
verbose:
  desc: null
  value: 1
num_timesteps:
  desc: null
  value: 0
_total_timesteps:
  desc: null
  value: 104857600
_num_timesteps_at_start:
  desc: null
  value: 0
action_noise:
  desc: null
  value: None
start_time:
  desc: null
  value: 1744848847129790202
tensorboard_log:
  desc: null
  value: runs/f2dtp8tt
_last_obs:
  desc: null
  value: "[[-0.05244064  0.3357544   0.440085   ...  0.          0.\n   0.       \
    \ ]\n [-0.05244064  0.3357544   0.440085   ...  0.          0.\n   0.        ]\n\
    \ [-0.05244064  0.3357544   0.440085   ...  0.          0.\n   0.        ]\n ...\n\
    \ [-0.05244064  0.33575726  0.440085   ...  0.          0.\n   0.        ]\n [-0.05244064\
    \  0.33575678  0.440085   ...  0.          0.\n   0.        ]\n [-0.05244064 \
    \ 0.33575702  0.440085   ...  0.          0.\n   0.        ]]"
_last_episode_starts:
  desc: null
  value: '[ True  True  True ...  True  True  True]'
_last_original_obs:
  desc: null
  value: None
_episode_num:
  desc: null
  value: 0
use_sde:
  desc: null
  value: 'False'
sde_sample_freq:
  desc: null
  value: -1
_current_progress_remaining:
  desc: null
  value: 1.0
_stats_window_size:
  desc: null
  value: 100
ep_info_buffer:
  desc: null
  value: deque([], maxlen=100)
ep_success_buffer:
  desc: null
  value: deque([], maxlen=100)
_n_updates:
  desc: null
  value: 0
_custom_logger:
  desc: null
  value: 'False'
env:
  desc: null
  value: <Sb3VecEnvWrapper<OrderEnforcing<ManagerBasedRLEnv<UR5e-Reach-Pose-IK>>>>
_vec_normalize_env:
  desc: null
  value: None
observation_space:
  desc: null
  value: Box(-inf, inf, (20,), float32)
action_space:
  desc: null
  value: Box(-100.0, 100.0, (6,), float32)
n_envs:
  desc: null
  value: 2048
rollout_buffer_class:
  desc: null
  value: <class 'stable_baselines3.common.buffers.RolloutBuffer'>
rollout_buffer_kwargs:
  desc: null
  value: '{}'
clip_range_vf:
  desc: null
  value: None
normalize_advantage:
  desc: null
  value: 'True'
lr_schedule:
  desc: null
  value: <function get_schedule_fn.<locals>.<lambda> at 0x778eccfac940>
rollout_buffer:
  desc: null
  value: <stable_baselines3.common.buffers.RolloutBuffer object at 0x778eccfa4eb0>
_logger:
  desc: null
  value: <stable_baselines3.common.logger.Logger object at 0x778eafed5b40>
