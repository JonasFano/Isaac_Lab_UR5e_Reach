wandb_version: 1

_wandb:
  desc: null
  value:
    python_version: 3.10.12
    cli_version: 0.19.9
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1744873095
    t:
      1:
      - 1
      - 55
      - 105
      2:
      - 1
      - 55
      - 105
      3:
      - 1
      - 2
      - 3
      - 14
      - 16
      - 22
      - 23
      - 35
      - 37
      4: 3.10.12
      5: 0.19.9
      8:
      - 5
      13: linux-x86_64
program:
  desc: null
  value: train_sb3_wandb_td3.py
method:
  desc: null
  value: grid
name:
  desc: null
  value: rel_ik_sb3_td3_ur5e_reach_0_05_pose_grid_search
metric:
  desc: null
  value:
    goal: maximize
    name: rollout/ep_rew_mean
parameters:
  desc: null
  value:
    seed:
      values:
      - 42
      - 24
    num_envs:
      value: 2048
    device:
      value: cuda:0
    n_timesteps:
      value: 104857600
    policy:
      value: MlpPolicy
    batch_size:
      values:
      - 256
      - 512
    gamma:
      value: 0.95
    learning_rate:
      values:
      - 1e-4
      - 3e-4
    train_freq:
      value: 4
    gradient_steps:
      value: 4
    buffer_size:
      value: 1000000
    policy_delay:
      value: 2
    learning_starts:
      value: 1000
    tau:
      value: 0.02
    target_policy_noise:
      values:
      - 0.2
      - 0.4
    target_noise_clip:
      values:
      - 0.2
      - 0.4
    action_noise:
      value: NormalActionNoise
    action_sigma:
      value: 0.01
    policy_kwargs:
      parameters:
        activation_fn:
          values:
          - nn.ELU
          - nn.ReLU
          - nn.Tanh
        net_arch:
          value:
          - 256
          - 128
    normalize_input:
      value: false
    normalize_value:
      value: false
    clip_obs:
      value: 50.0
action_noise:
  desc: null
  value: NormalActionNoise
action_sigma:
  desc: null
  value: 0.01
batch_size:
  desc: null
  value: 256
buffer_size:
  desc: null
  value: 1000000
clip_obs:
  desc: null
  value: 50
device:
  desc: null
  value: cuda:0
gamma:
  desc: null
  value: 0.95
gradient_steps:
  desc: null
  value: 4
learning_rate:
  desc: null
  value: 0.0001
learning_starts:
  desc: null
  value: 1000
n_timesteps:
  desc: null
  value: 104857600
normalize_input:
  desc: null
  value: false
normalize_value:
  desc: null
  value: false
num_envs:
  desc: null
  value: 2048
policy:
  desc: null
  value: MlpPolicy
policy_delay:
  desc: null
  value: 2
policy_kwargs:
  desc: null
  value:
    activation_fn: nn.ELU
    net_arch:
    - 256
    - 128
seed:
  desc: null
  value: 42
target_noise_clip:
  desc: null
  value: 0.4
target_policy_noise:
  desc: null
  value: 0.4
tau:
  desc: null
  value: 0.02
train_freq:
  desc: null
  value: 4
algo:
  desc: null
  value: TD3
policy_class:
  desc: null
  value: <class 'stable_baselines3.td3.policies.TD3Policy'>
verbose:
  desc: null
  value: 1
num_timesteps:
  desc: null
  value: 0
_total_timesteps:
  desc: null
  value: 104857600
_num_timesteps_at_start:
  desc: null
  value: 0
start_time:
  desc: null
  value: 1744873100133566513
tensorboard_log:
  desc: null
  value: runs/kmg9cebl
_last_obs:
  desc: null
  value: "[[-0.05244064  0.3357544   0.440085   ...  0.          0.\n   0.       \
    \ ]\n [-0.05244064  0.3357544   0.440085   ...  0.          0.\n   0.        ]\n\
    \ [-0.05244064  0.3357544   0.440085   ...  0.          0.\n   0.        ]\n ...\n\
    \ [-0.05244064  0.33575726  0.440085   ...  0.          0.\n   0.        ]\n [-0.05244064\
    \  0.33575678  0.440085   ...  0.          0.\n   0.        ]\n [-0.05244064 \
    \ 0.33575702  0.440085   ...  0.          0.\n   0.        ]]"
_last_episode_starts:
  desc: null
  value: '[ True  True  True ...  True  True  True]'
_last_original_obs:
  desc: null
  value: None
_episode_num:
  desc: null
  value: 0
use_sde:
  desc: null
  value: 'False'
sde_sample_freq:
  desc: null
  value: -1
_current_progress_remaining:
  desc: null
  value: 1.0
_stats_window_size:
  desc: null
  value: 100
ep_info_buffer:
  desc: null
  value: deque([], maxlen=100)
ep_success_buffer:
  desc: null
  value: deque([], maxlen=100)
_n_updates:
  desc: null
  value: 0
_custom_logger:
  desc: null
  value: 'False'
env:
  desc: null
  value: <Sb3VecEnvWrapper<OrderEnforcing<ManagerBasedRLEnv<UR5e-Reach-Pose-IK>>>>
_vec_normalize_env:
  desc: null
  value: None
observation_space:
  desc: null
  value: Box(-inf, inf, (20,), float32)
action_space:
  desc: null
  value: Box(-100.0, 100.0, (6,), float32)
n_envs:
  desc: null
  value: 2048
optimize_memory_usage:
  desc: null
  value: 'False'
replay_buffer:
  desc: null
  value: <stable_baselines3.common.buffers.ReplayBuffer object at 0x7723c739d270>
replay_buffer_class:
  desc: null
  value: <class 'stable_baselines3.common.buffers.ReplayBuffer'>
replay_buffer_kwargs:
  desc: null
  value: '{}'
_episode_storage:
  desc: null
  value: None
use_sde_at_warmup:
  desc: null
  value: 'False'
lr_schedule:
  desc: null
  value: <function get_schedule_fn.<locals>.<lambda> at 0x7723c73a4820>
actor:
  desc: null
  value: "Actor(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1,\
    \ end_dim=-1)\n  )\n  (mu): Sequential(\n    (0): Linear(in_features=20, out_features=256,\
    \ bias=True)\n    (1): ELU(alpha=1.0)\n    (2): Linear(in_features=256, out_features=128,\
    \ bias=True)\n    (3): ELU(alpha=1.0)\n    (4): Linear(in_features=128, out_features=6,\
    \ bias=True)\n    (5): Tanh()\n  )\n)"
actor_target:
  desc: null
  value: "Actor(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1,\
    \ end_dim=-1)\n  )\n  (mu): Sequential(\n    (0): Linear(in_features=20, out_features=256,\
    \ bias=True)\n    (1): ELU(alpha=1.0)\n    (2): Linear(in_features=256, out_features=128,\
    \ bias=True)\n    (3): ELU(alpha=1.0)\n    (4): Linear(in_features=128, out_features=6,\
    \ bias=True)\n    (5): Tanh()\n  )\n)"
critic:
  desc: null
  value: "ContinuousCritic(\n  (features_extractor): FlattenExtractor(\n    (flatten):\
    \ Flatten(start_dim=1, end_dim=-1)\n  )\n  (qf0): Sequential(\n    (0): Linear(in_features=26,\
    \ out_features=256, bias=True)\n    (1): ELU(alpha=1.0)\n    (2): Linear(in_features=256,\
    \ out_features=128, bias=True)\n    (3): ELU(alpha=1.0)\n    (4): Linear(in_features=128,\
    \ out_features=1, bias=True)\n  )\n  (qf1): Sequential(\n    (0): Linear(in_features=26,\
    \ out_features=256, bias=True)\n    (1): ELU(alpha=1.0)\n    (2): Linear(in_features=256,\
    \ out_features=128, bias=True)\n    (3): ELU(alpha=1.0)\n    (4): Linear(in_features=128,\
    \ out_features=1, bias=True)\n  )\n)"
critic_target:
  desc: null
  value: "ContinuousCritic(\n  (features_extractor): FlattenExtractor(\n    (flatten):\
    \ Flatten(start_dim=1, end_dim=-1)\n  )\n  (qf0): Sequential(\n    (0): Linear(in_features=26,\
    \ out_features=256, bias=True)\n    (1): ELU(alpha=1.0)\n    (2): Linear(in_features=256,\
    \ out_features=128, bias=True)\n    (3): ELU(alpha=1.0)\n    (4): Linear(in_features=128,\
    \ out_features=1, bias=True)\n  )\n  (qf1): Sequential(\n    (0): Linear(in_features=26,\
    \ out_features=256, bias=True)\n    (1): ELU(alpha=1.0)\n    (2): Linear(in_features=256,\
    \ out_features=128, bias=True)\n    (3): ELU(alpha=1.0)\n    (4): Linear(in_features=128,\
    \ out_features=1, bias=True)\n  )\n)"
actor_batch_norm_stats:
  desc: null
  value: '[]'
critic_batch_norm_stats:
  desc: null
  value: '[]'
actor_batch_norm_stats_target:
  desc: null
  value: '[]'
critic_batch_norm_stats_target:
  desc: null
  value: '[]'
_logger:
  desc: null
  value: <stable_baselines3.common.logger.Logger object at 0x7723ad3da500>
