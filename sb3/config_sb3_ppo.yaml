program: train_sb3_wandb_ppo.py
method: grid
name: rel_ik_sb3_ppo_ur5e_reach_0_05_pose_hand_e_stiffness_10000000_v5
metric:
  goal: maximize
  name: rollout/ep_rew_mean

parameters:
  seed:
    values: [42, 24]

  num_envs:
    value: 2048

  n_timesteps: # iteration * n_steps * nenvs: 400 * 64 * 8192 = 209715200
    value: 131072000 # 262144000 # 131072000 # 65536000 # 91750400 # 98304000

  policy:
    value: 'MlpPolicy'

  n_steps:
    value: 64

  batch_size:
    value: 16384

  gae_lambda:
    value: 0.95

  gamma:
    value: 0.95

  n_epochs:
    value: 8

  ent_coef: # Possibly change this to encourange more exploration
    value: 0.01

  vf_coef:
    value: 0.1

  learning_rate:
    value: !!float 3e-4

  clip_range:
    value: 0.2

  policy_kwargs:
    parameters:
      activation_fn: 
        value: nn.Tanh
      net_arch:
        parameters:
          pi:
            value: [128, 64]
          vf:
            value: [128, 64]

  target_kl:
    value: 0.02

  max_grad_norm:
    value: 1.0

  normalize_input:
    value: False

  normalize_value:
    value: False

  clip_obs:
    value: 50.0