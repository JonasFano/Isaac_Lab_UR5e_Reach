diff --git a/README.md b/README.md
index e98b455..a4b6220 100644
--- a/README.md
+++ b/README.md
@@ -45,4 +45,4 @@ wandb agent jofan23-university-of-southern-denmark/rel_ik_sb3_ppo_ur5e_reach_0_1
 
 wandb agent jofan23-university-of-southern-denmark/rel_ik_sb3_ppo_ur5e_reach_0_1_corrected/s5h00sc3
 
-wandb agent jofan23-university-of-southern-denmark/rel_ik_sb3_ppo_ur5e_reach_0_05_position/xvaf23h3
\ No newline at end of file
+wandb agent jofan23-university-of-southern-denmark/rel_ik_sb3_ppo_ur5e_reach_0_05_position/8m4yma1b
\ No newline at end of file
diff --git a/wandb/debug-cli.jofa.log b/wandb/debug-cli.jofa.log
index 7d5f887..ff47f78 100644
--- a/wandb/debug-cli.jofa.log
+++ b/wandb/debug-cli.jofa.log
@@ -458,3 +458,164 @@
 	vf_coef: 0.1
 2024-11-30 23:44:44 INFO About to run command: /usr/bin/env python train_sb3_wandb.py --batch_size=16384 --clip_obs=50 --clip_range=0.2 --ent_coef=0.01 --gae_lambda=0.95 --gamma=0.99 --learning_rate=0.0001 --max_grad_norm=1 --n_epochs=8 --n_steps=64 --n_timesteps=209715200 --normalize_input=False --normalize_value=False --policy=MlpPolicy "--policy_kwargs={'activation_fn': 'nn.ELU', 'net_arch': {'pi': [128, 64], 'vf': [128, 64]}}" --seed=42 --target_kl=0.02 --vf_coef=0.1
 2024-11-30 23:44:49 INFO Running runs: ['ivonn556']
+2024-12-02 10:40:20 INFO Running runs: []
+2024-12-02 10:40:21 INFO Agent received command: run
+2024-12-02 10:40:21 INFO Agent starting run with config:
+	batch_size: 2048
+	clip_obs: 50
+	clip_range: 0.2
+	ent_coef: 0.01
+	gae_lambda: 0.95
+	gamma: 0.99
+	learning_rate: 0.0001
+	max_grad_norm: 1
+	n_epochs: 8
+	n_steps: 64
+	n_timesteps: 209715200
+	normalize_input: False
+	normalize_value: True
+	policy: MlpPolicy
+	policy_kwargs: {'activation_fn': 'nn.ELU', 'net_arch': {'pi': [128, 64], 'vf': [128, 64]}}
+	seed: 42
+	target_kl: 0.02
+	vf_coef: 0.1
+2024-12-02 10:40:21 INFO About to run command: /usr/bin/env python train_sb3_wandb.py --batch_size=2048 --clip_obs=50 --clip_range=0.2 --ent_coef=0.01 --gae_lambda=0.95 --gamma=0.99 --learning_rate=0.0001 --max_grad_norm=1 --n_epochs=8 --n_steps=64 --n_timesteps=209715200 --normalize_input=False --normalize_value=True --policy=MlpPolicy "--policy_kwargs={'activation_fn': 'nn.ELU', 'net_arch': {'pi': [128, 64], 'vf': [128, 64]}}" --seed=42 --target_kl=0.02 --vf_coef=0.1
+2024-12-02 10:40:26 INFO Running runs: ['xh31w70q']
+2024-12-02 12:33:11 INFO Cleaning up finished run: xh31w70q
+2024-12-02 12:33:12 INFO Agent received command: run
+2024-12-02 12:33:12 INFO Agent starting run with config:
+	batch_size: 2048
+	clip_obs: 50
+	clip_range: 0.2
+	ent_coef: 0.01
+	gae_lambda: 0.95
+	gamma: 0.99
+	learning_rate: 0.0001
+	max_grad_norm: 1
+	n_epochs: 8
+	n_steps: 64
+	n_timesteps: 209715200
+	normalize_input: False
+	normalize_value: False
+	policy: MlpPolicy
+	policy_kwargs: {'activation_fn': 'nn.ELU', 'net_arch': {'pi': [128, 64], 'vf': [128, 64]}}
+	seed: 42
+	target_kl: 0.02
+	vf_coef: 0.1
+2024-12-02 12:33:12 INFO About to run command: /usr/bin/env python train_sb3_wandb.py --batch_size=2048 --clip_obs=50 --clip_range=0.2 --ent_coef=0.01 --gae_lambda=0.95 --gamma=0.99 --learning_rate=0.0001 --max_grad_norm=1 --n_epochs=8 --n_steps=64 --n_timesteps=209715200 --normalize_input=False --normalize_value=False --policy=MlpPolicy "--policy_kwargs={'activation_fn': 'nn.ELU', 'net_arch': {'pi': [128, 64], 'vf': [128, 64]}}" --seed=42 --target_kl=0.02 --vf_coef=0.1
+2024-12-02 12:33:17 INFO Running runs: ['iorj5s3p']
+2024-12-02 14:25:54 INFO Cleaning up finished run: iorj5s3p
+2024-12-02 14:25:54 INFO Agent received command: run
+2024-12-02 14:25:54 INFO Agent starting run with config:
+	batch_size: 2048
+	clip_obs: 50
+	clip_range: 0.2
+	ent_coef: 0.001
+	gae_lambda: 0.95
+	gamma: 0.99
+	learning_rate: 0.0001
+	max_grad_norm: 1
+	n_epochs: 8
+	n_steps: 64
+	n_timesteps: 209715200
+	normalize_input: False
+	normalize_value: True
+	policy: MlpPolicy
+	policy_kwargs: {'activation_fn': 'nn.ELU', 'net_arch': {'pi': [128, 64], 'vf': [128, 64]}}
+	seed: 42
+	target_kl: 0.02
+	vf_coef: 0.1
+2024-12-02 14:25:54 INFO About to run command: /usr/bin/env python train_sb3_wandb.py --batch_size=2048 --clip_obs=50 --clip_range=0.2 --ent_coef=0.001 --gae_lambda=0.95 --gamma=0.99 --learning_rate=0.0001 --max_grad_norm=1 --n_epochs=8 --n_steps=64 --n_timesteps=209715200 --normalize_input=False --normalize_value=True --policy=MlpPolicy "--policy_kwargs={'activation_fn': 'nn.ELU', 'net_arch': {'pi': [128, 64], 'vf': [128, 64]}}" --seed=42 --target_kl=0.02 --vf_coef=0.1
+2024-12-02 14:25:59 INFO Running runs: ['g9zyfi43']
+2024-12-02 16:20:04 INFO Cleaning up finished run: g9zyfi43
+2024-12-02 16:20:05 INFO Agent received command: run
+2024-12-02 16:20:05 INFO Agent starting run with config:
+	batch_size: 2048
+	clip_obs: 50
+	clip_range: 0.2
+	ent_coef: 0.001
+	gae_lambda: 0.95
+	gamma: 0.99
+	learning_rate: 0.0001
+	max_grad_norm: 1
+	n_epochs: 8
+	n_steps: 64
+	n_timesteps: 209715200
+	normalize_input: False
+	normalize_value: False
+	policy: MlpPolicy
+	policy_kwargs: {'activation_fn': 'nn.ELU', 'net_arch': {'pi': [128, 64], 'vf': [128, 64]}}
+	seed: 42
+	target_kl: 0.02
+	vf_coef: 0.1
+2024-12-02 16:20:05 INFO About to run command: /usr/bin/env python train_sb3_wandb.py --batch_size=2048 --clip_obs=50 --clip_range=0.2 --ent_coef=0.001 --gae_lambda=0.95 --gamma=0.99 --learning_rate=0.0001 --max_grad_norm=1 --n_epochs=8 --n_steps=64 --n_timesteps=209715200 --normalize_input=False --normalize_value=False --policy=MlpPolicy "--policy_kwargs={'activation_fn': 'nn.ELU', 'net_arch': {'pi': [128, 64], 'vf': [128, 64]}}" --seed=42 --target_kl=0.02 --vf_coef=0.1
+2024-12-02 16:20:10 INFO Running runs: ['kjdxjur5']
+2024-12-02 18:13:56 INFO Cleaning up finished run: kjdxjur5
+2024-12-02 18:13:57 INFO Agent received command: run
+2024-12-02 18:13:57 INFO Agent starting run with config:
+	batch_size: 8192
+	clip_obs: 50
+	clip_range: 0.2
+	ent_coef: 0.01
+	gae_lambda: 0.95
+	gamma: 0.99
+	learning_rate: 0.0001
+	max_grad_norm: 1
+	n_epochs: 8
+	n_steps: 64
+	n_timesteps: 209715200
+	normalize_input: False
+	normalize_value: True
+	policy: MlpPolicy
+	policy_kwargs: {'activation_fn': 'nn.ELU', 'net_arch': {'pi': [128, 64], 'vf': [128, 64]}}
+	seed: 42
+	target_kl: 0.02
+	vf_coef: 0.1
+2024-12-02 18:13:57 INFO About to run command: /usr/bin/env python train_sb3_wandb.py --batch_size=8192 --clip_obs=50 --clip_range=0.2 --ent_coef=0.01 --gae_lambda=0.95 --gamma=0.99 --learning_rate=0.0001 --max_grad_norm=1 --n_epochs=8 --n_steps=64 --n_timesteps=209715200 --normalize_input=False --normalize_value=True --policy=MlpPolicy "--policy_kwargs={'activation_fn': 'nn.ELU', 'net_arch': {'pi': [128, 64], 'vf': [128, 64]}}" --seed=42 --target_kl=0.02 --vf_coef=0.1
+2024-12-02 18:14:02 INFO Running runs: ['ds94603l']
+2024-12-02 20:04:06 INFO Cleaning up finished run: ds94603l
+2024-12-02 20:04:06 INFO Agent received command: run
+2024-12-02 20:04:06 INFO Agent starting run with config:
+	batch_size: 8192
+	clip_obs: 50
+	clip_range: 0.2
+	ent_coef: 0.01
+	gae_lambda: 0.95
+	gamma: 0.99
+	learning_rate: 0.0001
+	max_grad_norm: 1
+	n_epochs: 8
+	n_steps: 64
+	n_timesteps: 209715200
+	normalize_input: False
+	normalize_value: False
+	policy: MlpPolicy
+	policy_kwargs: {'activation_fn': 'nn.ELU', 'net_arch': {'pi': [128, 64], 'vf': [128, 64]}}
+	seed: 42
+	target_kl: 0.02
+	vf_coef: 0.1
+2024-12-02 20:04:06 INFO About to run command: /usr/bin/env python train_sb3_wandb.py --batch_size=8192 --clip_obs=50 --clip_range=0.2 --ent_coef=0.01 --gae_lambda=0.95 --gamma=0.99 --learning_rate=0.0001 --max_grad_norm=1 --n_epochs=8 --n_steps=64 --n_timesteps=209715200 --normalize_input=False --normalize_value=False --policy=MlpPolicy "--policy_kwargs={'activation_fn': 'nn.ELU', 'net_arch': {'pi': [128, 64], 'vf': [128, 64]}}" --seed=42 --target_kl=0.02 --vf_coef=0.1
+2024-12-02 20:04:11 INFO Running runs: ['iibbqdu7']
+2024-12-02 21:53:39 INFO Cleaning up finished run: iibbqdu7
+2024-12-02 21:53:39 INFO Agent received command: run
+2024-12-02 21:53:39 INFO Agent starting run with config:
+	batch_size: 8192
+	clip_obs: 50
+	clip_range: 0.2
+	ent_coef: 0.001
+	gae_lambda: 0.95
+	gamma: 0.99
+	learning_rate: 0.0001
+	max_grad_norm: 1
+	n_epochs: 8
+	n_steps: 64
+	n_timesteps: 209715200
+	normalize_input: False
+	normalize_value: True
+	policy: MlpPolicy
+	policy_kwargs: {'activation_fn': 'nn.ELU', 'net_arch': {'pi': [128, 64], 'vf': [128, 64]}}
+	seed: 42
+	target_kl: 0.02
+	vf_coef: 0.1
+2024-12-02 21:53:39 INFO About to run command: /usr/bin/env python train_sb3_wandb.py --batch_size=8192 --clip_obs=50 --clip_range=0.2 --ent_coef=0.001 --gae_lambda=0.95 --gamma=0.99 --learning_rate=0.0001 --max_grad_norm=1 --n_epochs=8 --n_steps=64 --n_timesteps=209715200 --normalize_input=False --normalize_value=True --policy=MlpPolicy "--policy_kwargs={'activation_fn': 'nn.ELU', 'net_arch': {'pi': [128, 64], 'vf': [128, 64]}}" --seed=42 --target_kl=0.02 --vf_coef=0.1
+2024-12-02 21:53:44 INFO Running runs: ['zk53lx00']
diff --git a/wandb/debug-internal.log b/wandb/debug-internal.log
index 0bd91df..3b62f5c 120000
--- a/wandb/debug-internal.log
+++ b/wandb/debug-internal.log
@@ -1 +1 @@
-run-20241130_234449-ivonn556/logs/debug-internal.log
\ No newline at end of file
+run-20241202_215344-zk53lx00/logs/debug-internal.log
\ No newline at end of file
diff --git a/wandb/debug.log b/wandb/debug.log
index 9cb861c..2a2df75 120000
--- a/wandb/debug.log
+++ b/wandb/debug.log
@@ -1 +1 @@
-run-20241130_234449-ivonn556/logs/debug.log
\ No newline at end of file
+run-20241202_215344-zk53lx00/logs/debug.log
\ No newline at end of file
diff --git a/wandb/latest-run b/wandb/latest-run
index 1922dc3..c8b2585 120000
--- a/wandb/latest-run
+++ b/wandb/latest-run
@@ -1 +1 @@
-run-20241130_234449-ivonn556
\ No newline at end of file
+run-20241202_215344-zk53lx00
\ No newline at end of file
