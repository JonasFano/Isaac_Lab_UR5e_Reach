# Reference: https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/hyperparams/ppo.yml#L32
seed: 42

# epoch * n_steps * nenvs: 200 * 64 * 4096 = 52428800
# epoch * n_steps * nenvs: 400 * 64 * 8192 = 209715200
# epochs = iterations
n_timesteps: 209715200
policy: 'MlpPolicy'
n_steps: 64
batch_size: 2048 # 192
gae_lambda: 0.95
gamma: 0.99
n_epochs: 8
ent_coef: 0.001
vf_coef: 0.1
learning_rate: !!float 1e-4 #3e-4
clip_range: 0.2
policy_kwargs: "dict(
                  activation_fn=nn.ELU,
                  net_arch=dict(pi=[128, 64], vf=[128, 64])
                )"
target_kl: 0.02
max_grad_norm: 1.0

# Uses VecNormalize class to normalize obs
normalize_input: False
# Uses VecNormalize class to normalize rew
normalize_value: False
clip_obs: None #100
