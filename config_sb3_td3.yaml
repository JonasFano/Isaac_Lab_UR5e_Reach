# Reference: https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/hyperparams/sac.yml
program: train_sb3_wandb_td3.py
method: grid
name: rel_ik_sb3_td3_ur5e_reach_0_05_pose
metric:
  goal: maximize
  name: rollout/ep_rew_mean

parameters:
  seed:
    value: 42

  n_timesteps: # iteration * n_steps * nenvs: 400 * 64 * 8192 = 209715200
    value: 209715200

  policy:
    value: 'MlpPolicy'

  batch_size:
    values: [256, 8192] 

  gamma:
    value: 0.99

  learning_rate:
    values: [1e-4, 3e-4]

  train_freq:
    value: 4

  gradient_steps:
    value: 4

  buffer_size: 
    value: 1000000

  policy_delay:
    value: 2

  learning_starts: 
    value: 10000

  tau: 
    value: 0.02

  target_policy_noise:
    value: 0.2

  target_noise_clip:
    value: 0.5

  policy_kwargs:
    parameters:
      activation_fn: 
        value: nn.ELU
      net_arch:
        values: [[300, 300], [256, 128], [128, 64]]


  normalize_input:
    value: False

  normalize_value:
    value: False

  clip_obs:
    value: 50.0