program: train_sb3_wandb.py
method: grid
name: rel_ik_sb3_ppo_ur5e_reach
metric:
  goal: minimize
  name: train/loss

parameters:
  seed:
    value: 42

  n_timesteps: # iteration * n_steps * nenvs: 200 * 64 * 4096 = 52428800
    value: 209715200

  policy:
    value: 'MlpPolicy'

  n_steps:
    value: 64

  batch_size:
    values: [2048, 8192, 16384]

  gae_lambda:
    value: 0.95

  gamma:
    value: 0.99

  n_epochs:
    value: 8

  ent_coef: # Possibly change this to encourange more exploration
    value: [0.01, 0.001]

  vf_coef:
    values: [2, 0.1, 0.0001]

  learning_rate:
    values: [1e-4, 1e-3]

  clip_range:
    value: 0.2

  policy_kwargs:
    parameters:
      activation_fn: 
        value: nn.ELU
      net_arch:
        parameters:
          pi:
            values: [[256, 128], [64, 64], [128, 64]]
          vf:
            values: [[256, 128], [64, 64], [128, 64]]

  target_kl:
    value: 0.02

  max_grad_norm:
    value: 1.0

  normalize_input:
    values: [True, False]

  normalize_value:
    values: [True, False]

  clip_obs:
    value: [100, 50, 5]