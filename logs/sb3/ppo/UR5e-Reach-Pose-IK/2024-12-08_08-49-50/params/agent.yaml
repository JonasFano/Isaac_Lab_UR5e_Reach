seed: 42
n_timesteps: 52428800
policy: MlpPolicy
batch_size: 256
gamma: 0.99
ent_coef: auto
learning_rate: 0.0003
train_freq: 8
gradient_steps: 8
target_update_interval: 1
target_entropy: -6
buffer_size: 1000000
learning_starts: 10000
tau: 0.02
use_sde: true
policy_kwargs: dict( activation_fn=nn.ELU, net_arch=[256, 256] )
normalize_input: false
normalize_value: false
clip_obs: 50.0
